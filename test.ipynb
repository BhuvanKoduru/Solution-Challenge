{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import imghdr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_dir = 'data' \n",
    "data_dir = 'combined copy' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5793 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "data = tf.keras.utils.image_dataset_from_directory('combined copy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_iterator = data.as_numpy_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-29 23:51:01.909125: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    }
   ],
   "source": [
    "batch = data_iterator.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=4, figsize=(20,20))\n",
    "for idx, img in enumerate(batch[0][:4]):\n",
    "    ax[idx].imshow(img.astype(int))\n",
    "    ax[idx].title.set_text(batch[1][idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/abhilashhathwar/miniforge3/lib/python3.10/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
     ]
    }
   ],
   "source": [
    "data = data.map(lambda x,y: (x/255, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(len(data)*.7)\n",
    "val_size = int(len(data)*.2)\n",
    "test_size = int(len(data)*.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data.take(train_size)\n",
    "val = data.skip(train_size).take(val_size)\n",
    "test = data.skip(train_size+val_size).take(test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = tf.keras.models.Sequential()\n",
    "# model.add(Conv2D(16, (3,3), 1, activation='relu', input_shape=(256,256,3)))\n",
    "# model.add(MaxPooling2D())\n",
    "# model.add(Conv2D(32, (3,3), 1, activation='relu'))\n",
    "# model.add(MaxPooling2D())\n",
    "# model.add(Conv2D(16, (3,3), 1, activation='relu'))\n",
    "# model.add(MaxPooling2D())\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(256, activation='relu'))\n",
    "# model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(16, (3, 3), activation=\"relu\", input_shape=(256, 256, 3), kernel_initializer='he_uniform'),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation=\"relu\",kernel_initializer='he_uniform'),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.Conv2D(16, (3, 3), activation=\"relu\",kernel_initializer='he_uniform'),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(256, activation=\"relu\",kernel_initializer='he_uniform'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(1, activation=\"sigmoid\",kernel_initializer='glorot_uniform')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.compile('adam', loss=tf.losses.BinaryCrossentropy(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 254, 254, 16)      448       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 127, 127, 16)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 125, 125, 32)      4640      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 62, 62, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 60, 60, 16)        4624      \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 57600)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               14745856  \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,755,825\n",
      "Trainable params: 14,755,825\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "logdir='logs'\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "127/127 [==============================] - 52s 400ms/step - loss: 2.3142 - accuracy: 0.5544 - val_loss: 0.6790 - val_accuracy: 0.6102\n",
      "Epoch 2/20\n",
      "127/127 [==============================] - 55s 427ms/step - loss: 0.5728 - accuracy: 0.7170 - val_loss: 0.6124 - val_accuracy: 0.6649\n",
      "Epoch 3/20\n",
      "127/127 [==============================] - 58s 456ms/step - loss: 0.4134 - accuracy: 0.8250 - val_loss: 0.5846 - val_accuracy: 0.6866\n",
      "Epoch 4/20\n",
      "127/127 [==============================] - 57s 445ms/step - loss: 0.2412 - accuracy: 0.9090 - val_loss: 0.5938 - val_accuracy: 0.7109\n",
      "Epoch 5/20\n",
      "127/127 [==============================] - 59s 463ms/step - loss: 0.1369 - accuracy: 0.9545 - val_loss: 0.6323 - val_accuracy: 0.7474\n",
      "Epoch 6/20\n",
      "127/127 [==============================] - 60s 472ms/step - loss: 0.0687 - accuracy: 0.9801 - val_loss: 0.8356 - val_accuracy: 0.7274\n",
      "Epoch 7/20\n",
      "127/127 [==============================] - 65s 507ms/step - loss: 0.0361 - accuracy: 0.9904 - val_loss: 0.7602 - val_accuracy: 0.7361\n",
      "Epoch 8/20\n",
      "127/127 [==============================] - 67s 520ms/step - loss: 0.0320 - accuracy: 0.9931 - val_loss: 0.8785 - val_accuracy: 0.7335\n",
      "Epoch 9/20\n",
      "127/127 [==============================] - 62s 482ms/step - loss: 0.0312 - accuracy: 0.9926 - val_loss: 0.8435 - val_accuracy: 0.7465\n",
      "Epoch 10/20\n",
      "127/127 [==============================] - 64s 499ms/step - loss: 0.0247 - accuracy: 0.9943 - val_loss: 1.1209 - val_accuracy: 0.7387\n",
      "Epoch 11/20\n",
      "127/127 [==============================] - 68s 533ms/step - loss: 0.0233 - accuracy: 0.9953 - val_loss: 0.9769 - val_accuracy: 0.7483\n",
      "Epoch 12/20\n",
      "127/127 [==============================] - 67s 524ms/step - loss: 0.0267 - accuracy: 0.9946 - val_loss: 0.9747 - val_accuracy: 0.7283\n",
      "Epoch 13/20\n",
      "127/127 [==============================] - 79s 615ms/step - loss: 0.0102 - accuracy: 0.9985 - val_loss: 1.1405 - val_accuracy: 0.7292\n",
      "Epoch 14/20\n",
      "127/127 [==============================] - 67s 526ms/step - loss: 0.0136 - accuracy: 0.9966 - val_loss: 1.2205 - val_accuracy: 0.7344\n",
      "Epoch 15/20\n",
      "127/127 [==============================] - 69s 537ms/step - loss: 0.0121 - accuracy: 0.9975 - val_loss: 1.1452 - val_accuracy: 0.7457\n",
      "Epoch 16/20\n",
      "127/127 [==============================] - 69s 542ms/step - loss: 0.0081 - accuracy: 0.9980 - val_loss: 1.2191 - val_accuracy: 0.7370\n",
      "Epoch 17/20\n",
      "127/127 [==============================] - 71s 555ms/step - loss: 0.0045 - accuracy: 0.9993 - val_loss: 1.1898 - val_accuracy: 0.7335\n",
      "Epoch 18/20\n",
      "127/127 [==============================] - 76s 592ms/step - loss: 0.0035 - accuracy: 0.9993 - val_loss: 1.4061 - val_accuracy: 0.7370\n",
      "Epoch 19/20\n",
      "127/127 [==============================] - 73s 573ms/step - loss: 0.0096 - accuracy: 0.9993 - val_loss: 1.2312 - val_accuracy: 0.7431\n",
      "Epoch 20/20\n",
      "127/127 [==============================] - 69s 539ms/step - loss: 0.0104 - accuracy: 0.9968 - val_loss: 1.1174 - val_accuracy: 0.7405\n"
     ]
    }
   ],
   "source": [
    "hist = model2.fit(train, epochs=20, validation_data=val, callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 442ms/step\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "1/1 [==============================] - 0s 92ms/step\n",
      "1/1 [==============================] - 0s 91ms/step\n",
      "1/1 [==============================] - 0s 97ms/step\n",
      "1/1 [==============================] - 0s 98ms/step\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "1/1 [==============================] - 0s 95ms/step\n",
      "1/1 [==============================] - 0s 97ms/step\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "1/1 [==============================] - 0s 91ms/step\n",
      "1/1 [==============================] - 0s 90ms/step\n",
      "1/1 [==============================] - 0s 91ms/step\n",
      "1/1 [==============================] - 0s 89ms/step\n",
      "1/1 [==============================] - 0s 90ms/step\n",
      "tf.Tensor(0.6692913, shape=(), dtype=float32) tf.Tensor(0.609319, shape=(), dtype=float32) tf.Tensor(0.6649306, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.metrics import Precision, Recall, BinaryAccuracy, \n",
    "pre = Precision()\n",
    "re = Recall()\n",
    "acc = BinaryAccuracy()\n",
    "f=F\n",
    "for batch in test.as_numpy_iterator(): \n",
    "    X, y = batch\n",
    "    yhat = model2.predict(X)\n",
    "    pre.update_state(y, yhat)\n",
    "    re.update_state(y, yhat)\n",
    "    acc.update_state(y, yhat)\n",
    "print(pre.result(), re.result(), acc.result())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodels\u001b[39;00m \u001b[39mimport\u001b[39;00m load_model\n\u001b[0;32m----> 2\u001b[0m model2\u001b[39m.\u001b[39msave(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(\u001b[39m'\u001b[39m\u001b[39mmodels\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39msoftstoryclassifier.h5\u001b[39m\u001b[39m'\u001b[39m))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model2' is not defined"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "model2.save(os.path.join('models','softstoryclassifier.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json = model2.to_json()\n",
    "with open(\"model4.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 11\u001b[0m\n\u001b[1;32m      7\u001b[0m json_file\u001b[39m.\u001b[39mclose()\n\u001b[1;32m      9\u001b[0m \u001b[39m# use Keras model_from_json to make a loaded model\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m loaded_model \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mmodels\u001b[39m.\u001b[39mmodel_from_json(loaded_model_json)\n\u001b[1;32m     13\u001b[0m \u001b[39m# load weights into new model\u001b[39;00m\n\u001b[1;32m     15\u001b[0m loaded_model\u001b[39m.\u001b[39mload_weights(\u001b[39m\"\u001b[39m\u001b[39msoftstoryclassifier.h5\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "#from keras import model_from_json \n",
    "\n",
    "# opening and store file in a variable\n",
    "\n",
    "json_file = open('model4.json','r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "\n",
    "# use Keras model_from_json to make a loaded model\n",
    "\n",
    "loaded_model = tf.keras.models.model_from_json(loaded_model_json)\n",
    "\n",
    "# load weights into new model\n",
    "\n",
    "loaded_model.load_weights(\"softstoryclassifier.h5\")\n",
    "print(\"Loaded Model from disk\")\n",
    "\n",
    "# compile and evaluate loaded model\n",
    "\n",
    "loaded_model.compile(loss=tf.losses.BinaryCrossentropy(),optimizer='adam',metrics=['accuracy'])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
